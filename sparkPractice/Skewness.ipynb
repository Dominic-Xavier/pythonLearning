{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PySpark_Hadoop\")\\\n",
    ".master(\"local[*]\")\\\n",
    ".config(\"spark.cores.max\", 2) \\\n",
    ".config(\"spark.executor.cores\", 1)\\\n",
    ".config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\\\n",
    ".config(\"spark.sql.adaptive.enabled\", False)\\\n",
    ".config(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\\\n",
    ".config(\"spark.sql.adaptive.skewJoin.enabled\", False)\\\n",
    ".config(\"spark.sql.catalogImplementation\", 2)\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n",
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.catalogImplementation\")\n",
    "spark.sql(\"show databases\").show()\n",
    "spark.sql(\"use default\")\n",
    "spark.sql(\"show tables\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df = spark.read.format(\"csv\").option(\"header\", True).load(\"file:////home/dominic/Desktop/pythonLearning/csvFiles/practice_Data/Interview_Preparation/transactions.csv\")\n",
    "\n",
    "users_df = spark.read.format(\"csv\").option(\"header\", True).load(\"file:////home/dominic/Desktop/pythonLearning/csvFiles/practice_Data/Interview_Preparation/users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------+\n",
      "|namespace|   tableName|isTemporary|\n",
      "+---------+------------+-----------+\n",
      "|         |transactions|       true|\n",
      "|         |       users|       true|\n",
      "+---------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transaction_df.createOrReplaceTempView(\"transactions\")\n",
    "users_df.createOrReplaceTempView(\"users\")\n",
    "spark.sql(\"show tables in default\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_table = spark.sql(\"select * from transactions\")\n",
    "uaer_table = spark.sql(\"select * from users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+-------+-----+-----------------+\n",
      "|txn_id|user_id|amount|      date|user_id| name|            email|\n",
      "+------+-------+------+----------+-------+-----+-----------------+\n",
      "|    T1|    101|   250|2025-06-01|    101|Alice|alice@example.com|\n",
      "|    T2|    101|   100|2025-06-01|    101|Alice|alice@example.com|\n",
      "|    T4|    101|   400|2025-06-03|    101|Alice|alice@example.com|\n",
      "|    T6|    104|   150|2025-06-04|    104|David|david@example.com|\n",
      "|    T3|    102|   300|2025-06-02|    102|  Bob|  bob@example.com|\n",
      "|    T5|    103|   200|2025-06-04|    103|Carol|carol@example.com|\n",
      "+------+-------+------+----------+-------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df = spark.sql(\"\"\"\n",
    "    select * from transactions t\n",
    "    join users u\n",
    "    on t.user_id = u.user_id\n",
    "\"\"\")\n",
    "user_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = transaction_df.join(users_df, transaction_df.user_id == users_df.user_id, \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joined_df.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
