{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PySpark_Hadoop\")\\\n",
    ".master(\"local[*]\")\\\n",
    ".config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\\\n",
    ".config(\"spark.sql.adaptive.enabled\", False)\\\n",
    ".config(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\\\n",
    ".config(\"spark.sql.adaptive.skewJoin.enabled\", False)\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session stopped successfully.\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "print(\"Spark Session stopped successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers DataFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales DataFrame\n",
      "Product DataFrame\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[product_id: string, product_name: string, category: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Customers DataFrame\")\n",
    "customer_df = spark.read.csv(\"file:////home/dominic/Desktop/pythonLearning/csvFiles/practice_Data/customers.csv\", header=True, inferSchema=False)\n",
    "customer_df = customer_df.repartition(4)\n",
    "\n",
    "print(\"Sales DataFrame\")\n",
    "sales_df = spark.read.csv(\"file:////home/dominic/Desktop/pythonLearning/csvFiles/practice_Data/sales.csv\", header=True, inferSchema=False)\n",
    "sales_df = sales_df.repartition(4)\n",
    "\n",
    "print(\"Product DataFrame\")\n",
    "products_df = spark.read.csv(\"file:////home/dominic/Desktop/pythonLearning/csvFiles/practice_Data/products.csv\", header=True, inferSchema=False)\n",
    "products_df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df_clean = sales_df.drop(\"region\").withColumnRenamed(\"customer_id\", \"customer_sales_id\") \\\n",
    ".withColumnRenamed(\"product_id\", \"product_sales_id\")\n",
    "sales_df_clean = sales_df_clean.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined DataFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Explicitly repartition each DF on its own join key\n",
    "sales_df_clean = sales_df_clean.repartition(4, col(\"product_sales_id\"))\n",
    "products_df = products_df.repartition(4, col(\"product_id\"))\n",
    "\n",
    "# Now join â€” this causes shuffle because Spark needs to align keys\n",
    "#joined_df = sales_df_clean.join(products_df, sales_df_clean.product_sales_id == products_df.product_id, \"inner\")\n",
    "\n",
    "print(\"Joined DataFrame\")\n",
    "\n",
    "joined_df = sales_df_clean.join(products_df, sales_df_clean.product_sales_id == products_df.product_id, \"inner\")\\\n",
    "    .join(customer_df, sales_df_clean.customer_sales_id == customer_df.customer_id, \"inner\")\n",
    "\n",
    "joined_df = joined_df.repartition(4)\n",
    "joined_df = joined_df.withColumn(\"TotalCost\", col(\"unit_price\") * col(\"quantity\"))\n",
    "#joined_df.groupBy(\"region\").count().show()\n",
    "joined_df.write.mode(\"overwrite\").parquet(\"file:////home/dominic/Desktop/pythonLearning/csvFiles/practice_Data/joined_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [order_id#40, order_date#41, customer_sales_id#84, product_sales_id#91, quantity#44, unit_price#45, product_id#71, product_name#72, category#73, customer_id#17, customer_name#18, region#19, ('unit_price * 'quantity) AS TotalCost#142]\n",
      "+- Repartition 4, true\n",
      "   +- Join Inner, (customer_sales_id#84 = customer_id#17)\n",
      "      :- Join Inner, (product_sales_id#91 = product_id#71)\n",
      "      :  :- RepartitionByExpression [product_sales_id#91], 4\n",
      "      :  :  +- Repartition 4, true\n",
      "      :  :     +- Project [order_id#40, order_date#41, customer_sales_id#84, product_id#43 AS product_sales_id#91, quantity#44, unit_price#45]\n",
      "      :  :        +- Project [order_id#40, order_date#41, customer_id#42 AS customer_sales_id#84, product_id#43, quantity#44, unit_price#45]\n",
      "      :  :           +- Project [order_id#40, order_date#41, customer_id#42, product_id#43, quantity#44, unit_price#45]\n",
      "      :  :              +- Repartition 4, true\n",
      "      :  :                 +- Relation [order_id#40,order_date#41,customer_id#42,product_id#43,quantity#44,unit_price#45,region#46] csv\n",
      "      :  +- RepartitionByExpression [product_id#71], 4\n",
      "      :     +- Relation [product_id#71,product_name#72,category#73] csv\n",
      "      +- Repartition 4, true\n",
      "         +- Relation [customer_id#17,customer_name#18,region#19] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "order_id: string, order_date: string, customer_sales_id: string, product_sales_id: string, quantity: string, unit_price: string, product_id: string, product_name: string, category: string, customer_id: string, customer_name: string, region: string, TotalCost: double\n",
      "Project [order_id#40, order_date#41, customer_sales_id#84, product_sales_id#91, quantity#44, unit_price#45, product_id#71, product_name#72, category#73, customer_id#17, customer_name#18, region#19, (cast(unit_price#45 as double) * cast(quantity#44 as double)) AS TotalCost#142]\n",
      "+- Repartition 4, true\n",
      "   +- Join Inner, (customer_sales_id#84 = customer_id#17)\n",
      "      :- Join Inner, (product_sales_id#91 = product_id#71)\n",
      "      :  :- RepartitionByExpression [product_sales_id#91], 4\n",
      "      :  :  +- Repartition 4, true\n",
      "      :  :     +- Project [order_id#40, order_date#41, customer_sales_id#84, product_id#43 AS product_sales_id#91, quantity#44, unit_price#45]\n",
      "      :  :        +- Project [order_id#40, order_date#41, customer_id#42 AS customer_sales_id#84, product_id#43, quantity#44, unit_price#45]\n",
      "      :  :           +- Project [order_id#40, order_date#41, customer_id#42, product_id#43, quantity#44, unit_price#45]\n",
      "      :  :              +- Repartition 4, true\n",
      "      :  :                 +- Relation [order_id#40,order_date#41,customer_id#42,product_id#43,quantity#44,unit_price#45,region#46] csv\n",
      "      :  +- RepartitionByExpression [product_id#71], 4\n",
      "      :     +- Relation [product_id#71,product_name#72,category#73] csv\n",
      "      +- Repartition 4, true\n",
      "         +- Relation [customer_id#17,customer_name#18,region#19] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [order_id#40, order_date#41, customer_sales_id#84, product_sales_id#91, quantity#44, unit_price#45, product_id#71, product_name#72, category#73, customer_id#17, customer_name#18, region#19, (cast(unit_price#45 as double) * cast(quantity#44 as double)) AS TotalCost#142]\n",
      "+- Repartition 4, true\n",
      "   +- Join Inner, (customer_sales_id#84 = customer_id#17)\n",
      "      :- Join Inner, (product_sales_id#91 = product_id#71)\n",
      "      :  :- RepartitionByExpression [product_sales_id#91], 4\n",
      "      :  :  +- Project [order_id#40, order_date#41, customer_sales_id#84, product_id#43 AS product_sales_id#91, quantity#44, unit_price#45]\n",
      "      :  :     +- Repartition 4, true\n",
      "      :  :        +- Project [order_id#40, order_date#41, customer_id#42 AS customer_sales_id#84, product_id#43, quantity#44, unit_price#45]\n",
      "      :  :           +- Filter (isnotnull(product_id#43) AND isnotnull(customer_id#42))\n",
      "      :  :              +- Relation [order_id#40,order_date#41,customer_id#42,product_id#43,quantity#44,unit_price#45,region#46] csv\n",
      "      :  +- RepartitionByExpression [product_id#71], 4\n",
      "      :     +- Filter isnotnull(product_id#71)\n",
      "      :        +- Relation [product_id#71,product_name#72,category#73] csv\n",
      "      +- Repartition 4, true\n",
      "         +- Filter isnotnull(customer_id#17)\n",
      "            +- Relation [customer_id#17,customer_name#18,region#19] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(11) Project [order_id#40, order_date#41, customer_sales_id#84, product_sales_id#91, quantity#44, unit_price#45, product_id#71, product_name#72, category#73, customer_id#17, customer_name#18, region#19, (cast(unit_price#45 as double) * cast(quantity#44 as double)) AS TotalCost#142]\n",
      "+- Exchange RoundRobinPartitioning(4), REPARTITION_BY_NUM, [plan_id=372]\n",
      "   +- *(10) SortMergeJoin [customer_sales_id#84], [customer_id#17], Inner\n",
      "      :- *(7) Sort [customer_sales_id#84 ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(customer_sales_id#84, 200), ENSURE_REQUIREMENTS, [plan_id=356]\n",
      "      :     +- *(6) SortMergeJoin [product_sales_id#91], [product_id#71], Inner\n",
      "      :        :- *(3) Sort [product_sales_id#91 ASC NULLS FIRST], false, 0\n",
      "      :        :  +- Exchange hashpartitioning(product_sales_id#91, 200), REPARTITION_BY_NUM, [plan_id=341]\n",
      "      :        :     +- *(2) Project [order_id#40, order_date#41, customer_sales_id#84, product_id#43 AS product_sales_id#91, quantity#44, unit_price#45]\n",
      "      :        :        +- Exchange RoundRobinPartitioning(4), REPARTITION_BY_NUM, [plan_id=337]\n",
      "      :        :           +- *(1) Project [order_id#40, order_date#41, customer_id#42 AS customer_sales_id#84, product_id#43, quantity#44, unit_price#45]\n",
      "      :        :              +- *(1) Filter (isnotnull(product_id#43) AND isnotnull(customer_id#42))\n",
      "      :        :                 +- FileScan csv [order_id#40,order_date#41,customer_id#42,product_id#43,quantity#44,unit_price#45] Batched: false, DataFilters: [isnotnull(product_id#43), isnotnull(customer_id#42)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/dominic/Desktop/pythonLearning/csvFiles/practice_Data/sales..., PartitionFilters: [], PushedFilters: [IsNotNull(product_id), IsNotNull(customer_id)], ReadSchema: struct<order_id:string,order_date:string,customer_id:string,product_id:string,quantity:string,uni...\n",
      "      :        +- *(5) Sort [product_id#71 ASC NULLS FIRST], false, 0\n",
      "      :           +- Exchange hashpartitioning(product_id#71, 200), REPARTITION_BY_NUM, [plan_id=349]\n",
      "      :              +- *(4) Filter isnotnull(product_id#71)\n",
      "      :                 +- FileScan csv [product_id#71,product_name#72,category#73] Batched: false, DataFilters: [isnotnull(product_id#71)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/dominic/Desktop/pythonLearning/csvFiles/practice_Data/produ..., PartitionFilters: [], PushedFilters: [IsNotNull(product_id)], ReadSchema: struct<product_id:string,product_name:string,category:string>\n",
      "      +- *(9) Sort [customer_id#17 ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(customer_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=365]\n",
      "            +- Exchange RoundRobinPartitioning(4), REPARTITION_BY_NUM, [plan_id=364]\n",
      "               +- *(8) Filter isnotnull(customer_id#17)\n",
      "                  +- FileScan csv [customer_id#17,customer_name#18,region#19] Batched: false, DataFilters: [isnotnull(customer_id#17)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/dominic/Desktop/pythonLearning/csvFiles/practice_Data/custo..., PartitionFilters: [], PushedFilters: [IsNotNull(customer_id)], ReadSchema: struct<customer_id:string,customer_name:string,region:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.explain(True)\n",
    "\n",
    "#This is a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Count:  24994\n",
      "+--------+----------+-----------------+----------------+--------+----------+----------+------------+-----------+-----------+-------------+------+---------+\n",
      "|order_id|order_date|customer_sales_id|product_sales_id|quantity|unit_price|product_id|product_name|   category|customer_id|customer_name|region|TotalCost|\n",
      "+--------+----------+-----------------+----------------+--------+----------+----------+------------+-----------+-----------+-------------+------+---------+\n",
      "| O003329|2023-02-28|            C0668|           P0060|       2|       977|     P0060|  Product_60|      Books|      C0668| Customer_668|  West|   1954.0|\n",
      "| O046886|2023-01-15|            C0798|           P0093|       3|       284|     P0093|  Product_93|      Books|      C0798| Customer_798|  West|    852.0|\n",
      "| O099476|2023-03-15|            C0798|           P0042|       3|      1846|     P0042|  Product_42|   Clothing|      C0798| Customer_798|  West|   5538.0|\n",
      "| O087157|2023-04-01|            C0798|           P0025|       3|      1845|     P0025|  Product_25|   Clothing|      C0798| Customer_798|  West|   5535.0|\n",
      "| O053180|2023-01-14|            C0059|           P0108|       3|      1897|     P0108| Product_108|  Furniture|      C0059|  Customer_59| South|   5691.0|\n",
      "| O080979|2023-01-29|            C0798|           P0122|       2|      1826|     P0122| Product_122|      Books|      C0798| Customer_798|  West|   3652.0|\n",
      "| O091770|2023-05-09|            C0668|           P0110|       2|       136|     P0110| Product_110|  Furniture|      C0668| Customer_668|  West|    272.0|\n",
      "| O000261|2023-03-06|            C0798|           P0079|       2|       899|     P0079|  Product_79|  Furniture|      C0798| Customer_798|  West|   1798.0|\n",
      "| O059364|2023-06-16|            C0798|           P0125|       3|       221|     P0125| Product_125|Electronics|      C0798| Customer_798|  West|    663.0|\n",
      "| O046279|2023-05-21|            C0798|           P0132|       3|       412|     P0132| Product_132|      Books|      C0798| Customer_798|  West|   1236.0|\n",
      "| O065685|2023-03-25|            C0668|           P0150|       2|       882|     P0150| Product_150|   Clothing|      C0668| Customer_668|  West|   1764.0|\n",
      "| O063745|2023-06-01|            C0059|           P0160|       2|      1960|     P0160| Product_160|  Furniture|      C0059|  Customer_59| South|   3920.0|\n",
      "| O059948|2023-01-03|            C0668|           P0015|       4|      1974|     P0015|  Product_15|      Books|      C0668| Customer_668|  West|   7896.0|\n",
      "| O010428|2023-03-20|            C0059|           P0140|       1|      1915|     P0140| Product_140|   Clothing|      C0059|  Customer_59| South|   1915.0|\n",
      "| O071639|2023-05-19|            C0798|           P0107|       4|      1106|     P0107| Product_107|Electronics|      C0798| Customer_798|  West|   4424.0|\n",
      "| O053143|2023-06-03|            C0668|           P0042|       1|      1918|     P0042|  Product_42|   Clothing|      C0668| Customer_668|  West|   1918.0|\n",
      "| O006661|2023-02-04|            C0798|           P0193|       2|       583|     P0193| Product_193|  Furniture|      C0798| Customer_798|  West|   1166.0|\n",
      "| O048795|2023-01-03|            C0668|           P0094|       3|       454|     P0094|  Product_94|Electronics|      C0668| Customer_668|  West|   1362.0|\n",
      "| O025079|2023-01-30|            C0668|           P0093|       1|       383|     P0093|  Product_93|      Books|      C0668| Customer_668|  West|    383.0|\n",
      "| O005947|2023-01-17|            C0798|           P0073|       2|      1106|     P0073|  Product_73|Electronics|      C0798| Customer_798|  West|   2212.0|\n",
      "+--------+----------+-----------------+----------------+--------+----------+----------+------------+-----------+-----------+-------------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"file:////home/dominic/Desktop/pythonLearning/csvFiles/practice_Data/joined_data.parquet/part-00003-b5faee99-bb6b-42c2-bd18-9b36c48703a1-c000.snappy.parquet\")\n",
    "print(\"DataFrame Count: \", df.count())\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
